Section 24.7 Locality
427
locality), or which are physically adjacent to recently referenced data
(spatial locality) [Denning, 1972]. A conventional cache exploits locality of
reference (both temporal and spatial) to hold actively used data in fast
memory close to the processor [Smith, 1982].
Functional programs are not so well behaved, since the physical adjacenty
of two cells in the heap bears no relation to their logical adjacenty, resulting in
a loss of spatial locality. This is, as we now discuss, particularly serious for
parallel machines.
Locality is a statistical property of programs, and the best we can hope to do
is to develop effective heuristics for achieving predominantly local references.
This is at present an area more of speculation than experiment, though some
simulations have been performed [Keller and Lin, 1984; Hudak and
Goldberg, 1985a].
24.7.2 Shared Memory and Distributed Memory
Broadly speaking, a parallel graph reduction machine can be organized in one
of two ways:
(i) In a shared memory machine the graph resides in a large shared memory
system, probably consisting of a number of distinct memory units. The
processors are connected to the memory system by some kind of
communications system and, as the number of processors increases, so
does the transit time of processor-memory transactions through the
communications system.
more slowly.
Hence, adding more processors causes the existing processors to run
(ii) In a distributed memory machine each processor has a local memory unit
attached to it, forming a composite processor/memory unit. The graph is
distributed among these local memory units. Processors access graph
nodes in remote memory units using a communications system which
interconnects all the processor/memory units.
Accessing a local graph node is therefore very much cheaper than
accessing a remote one. If local accesses predominate, then more
processors can be added without slowing down existing processors, a
very desirable property.
There is no reason in principle why accessing a remote graph node in a
distributed memory machine should take any longer than in a shared memory
machine (the communication system needs to be used in either case), and this
is one of the insights of the Rediflow architecture (see below).
We see, therefore, that to be able to add more processors to a machine
without slowing down the existing processors we must
(i) use a distributed memory scheme,
(ii) achieve locality.
