370
Chapter 21 Optimizing Generalized Tail Calls
(iii) the SQUEEZE takes the place of POP in getting rid of the parameters to
$F;
(iv) no UNWIND need take place because it is already done;
(v) no check need be made that W has enough parameters, since we know at
compile-time that it does.
These benefits only obtain, however, if
(i) we know what W is;
(ii) it takes just the right number of arguments.
In the ensuing section we will lift these restrictions.
Tail calls have been well studied in other contexts, and we now discuss
briefly how our new implementation compares with others.
The optimizing of tail calls has been a standard feature in Lisp compilers for
a long time (see Steele [1977], for example). Such compilers exploit the fact
that a tail call to a function W can be replaced by a jump to W, thus saving the
allocation of a new stack frame. A particular effect of this optimization is that
tail recursion (which normally consumes a stack frame for each call) is
transformed into iteration (which operates in constant space).
It is, however, a property of graph reduction that this optimization is
performed automatically [Turner, 1979]! Even the first implementation of
Chapter 18 performs tail recursion in constant stack space, and all our
optimizations preserve this property. The reason for this is that at the end of a
code sequence generated by the R scheme we used UNWIND to continue
evaluation on the same stack, rather than using EVAL which creates a new
stack. (Note: we differ here from the G-machine papers, which use EVAL at
the end of R, at least to begin with.)
While even simple graph reduction implementations can do tail recursion in
constant stack space, they still consume heap. Very many of the heap cells
thus consumed are discarded very soon after they are allocated, and it is the
cells.
purpose of the optimization we have described to avoid this turnover of heap
We make one final observation before proceeding to a more general
treatment of the spine. Consider the function
$H x = IF (= x 0) ($G 3 x) (+ 1 ($H (- x 1)))
where $G is a supercombinator which takes two arguments. The call to $G can
properly be considered a tail call, since once the decision has been taken to
take the 'then' branch of the IF, the result of the $H reduction is just ($G 3 x).
of an IF.
Hence we would like our tail call optimizations to propagate into the branches
Complete compilation schemes for tail calls are not given since they are an
easy consequence of the next section.
