Section 24.4 Sparking tasks
419
concurrent evaluation of components of data structures, so some sort of
strictness analysis on non-flat domains is probably essential (see Section
22.4.2).
It is, of course, crucial that algorithmic parallelism is exploited by the
system but, however clever the strictness analyzer is, the programmer will
always fear that it may fail to spot the carefully introduced parallelism in
particular cases. It seems desirable, therefore, that the programmer should be
allowed to annotate the program with strictness information. As a safety
feature the strictness analyzer could issue a warning message if the
this.
programmer annotates a function as strict when the analyzer fails to discover
24.4.4 Too Much Parallelism
The other side of the coin is that, even in a conservative regime, too much
parallelism may be generated. This can raise serious resource-management
problems, since during evaluation a graph often expands before it shrinks.
There is a danger that the entire memory of the machine might become filled
space.
with half-finished computations, none of which could proceed for lack of
For example, consider a program in which a function f returns a list which is
consumed by a function g, which examines the whole list. A clever strictness
analyzer would spot that g used the whole list and, using this information, the
implementation might set off a task to evaluate the whole list concurrently
with its examination by g. Unfortunately, if f runs much faster than g, the
memory of the machine might become filled with the intermediate list.
It seems likely that some kind of control over runaway parallelism of this
kind will be necessary. This is very much a research area, and little experience
has been accumulated so far.
24.4.5 Granularity, and the Problem of Tiny Tasks
In any parallel machine there is some administrative overhead associated with
sparking, executing and completing a task. It is important that this overhead is
small compared with the amount of work that the task does, otherwise the
machine is in danger of spending a large fraction of its resources in task
small.
administration. Hence we must ensure that the tasks we spark are not too
The tasks generated by a divide and conquer program can be thought of as a
tree, in which each node is a task and the descendants of a node are the
subtasks which it sparks.
In a binary tree about half the nodes are leaves, so in a binary divide and
conquer algorithm about half the tasks generated will be 'leaf tasks'; that is,
tasks which the algorithm does not split into subtasks. For example, in the
