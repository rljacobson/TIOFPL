Section 13.1 The idea of compilation
221
15).
beneficially be shared (we discuss this point in more detail in Chapter
A more efficient alternative to this is compilation, whereby we associate
with each lambda body a fixed sequence of instructions which will construct an
instance of the lambda body. Then the operation of instantiating a lambda
body would consist simply of obeying the sequence of instructions associated
with the lambda body.
This instruction sequence can be constructed in advance by a compiler, and
contains implicitly the knowledge about the shape of the body and where the
formal parameter occurs. Hence we would expect the compiled code to run
much faster than the Instantiate method, for just the same reasons that
compiled code runs faster than interpreted code in conventional languages. In
effect, all the tests in Instantiate are made in advance by the compiler.
Furthermore, it turns out that compilation opens up many new avenues for
optimization, which offer considerable further efficiency increases.
Unfortunately, not all lambda abstractions are amenable to compilation in
this way. Consider, for example, the lambda abstraction
Ax. (Ay . - y x)
When we apply the Ax abstraction to an argument, 3 say, we instantiate its
body, thus creating a brand new lambda abstraction (Ay.- y 3).
Furthermore, each application of the Ax abstraction to a different argument
will create a new and different xy abstraction, thus making a nonsense of our
hope to compile a single fixed code sequence for each lambda abstraction.
The problem is that x occurs free in the body of the xy abstraction, so that
we have to make a new instance of the Ay abstraction whenever x is bound to a
new value by an application of the Ax abstraction. In the case of lambda
abstractions which have no free variables there is no problem, and we can
compile a code sequence for it as outlined above.
One way around this problem would be to allow the code sequence to
access the values of the free variables in some way, thus parameterizing the
code sequence on the values of the free variables. This approach leads us to
the SECD machine [Landin, 1964; Henderson, 1980], in which the code
sequence for a lambda abstraction has access to an environment which
contains values for each of the free variables, thus allowing a single code
sequence for each lambda abstraction. It is also the route followed by all
block-structured languages, in which the values of free variables are found by
looking in the appropriate stack frame.
In this book, however, we will study a totally different approach, called
supercombinator graph reduction, which does not require the addition of an
environment to our model of graph reduction. The idea is to transform the
program into an equivalent one in which all the lambda abstractions are
amenable to compilation. This transformation algorithm, which is called
lambda-lifting, is of considerable interest in its own right, and we devote the
